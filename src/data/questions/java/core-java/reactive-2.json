{
  "category": "Core Java",
  "subcategory": "Reactive",
  "questions": [
    {
      "id": "java-reactive-use-cases-core-java-r-11",
      "skillLevel": "basic",
      "shortTitle": "Practical Use Cases",
      "question": "What are some practical use cases where reactive programming in Java provides significant benefits?",
      "answerInsights": [
        {
          "category": "Basic",
          "points": [
            {
              "title": "High-Concurrency Web Applications",
              "description": "Web applications that need to handle many concurrent users benefit from reactive programming's non-blocking nature. Server resources can be used more efficiently, often handling more concurrent connections with the same hardware compared to traditional blocking approaches. This makes reactive programming ideal for high-traffic websites, API gateways, and real-time web applications where the server needs to maintain many simultaneous client connections without exhausting system resources."
            },
            {
              "title": "Real-time Data Processing",
              "description": "Applications that process continuous streams of data (like monitoring systems, analytics platforms, or IoT data collection) can use reactive streams to handle data flow in a controlled manner with backpressure, preventing system overload when data surges occur. Examples include financial market data processing, social media feeds, sensor networks, and log aggregation systems where data volumes can fluctuate dramatically and the ability to handle backpressure is crucial for system stability."
            },
            {
              "title": "External API Integration",
              "description": "When applications need to integrate with multiple external services, reactive programming allows orchestrating and combining these calls efficiently. This is especially useful when API responses need to be combined, transformed, or when sequential calls depend on previous results. Reactive approaches shine in microservice architectures where one request might trigger multiple downstream service calls that can be executed concurrently or in complex sequences, all while maintaining a responsive user experience."
            }
          ]
        },
        {
          "category": "Intermediate",
          "points": [
            {
              "title": "Event-Driven Microservices",
              "description": "Microservices architectures that communicate via events can leverage reactive programming for processing event streams. The declarative nature of reactive code simplifies handling event routing, transformation, enrichment, and error recovery. This is particularly valuable in architectures using event sourcing or CQRS (Command Query Responsibility Segregation) patterns, where events are the primary means of communication and state propagation between services. Reactive frameworks like Spring WebFlux combined with event brokers (Kafka, RabbitMQ) create a powerful foundation for scalable event-driven systems."
            },
            {
              "title": "Long-Polling and Server-Sent Events",
              "description": "Applications that use long-polling or Server-Sent Events (SSE) to push updates to clients benefit from reactive programming's ability to keep many connections open efficiently without blocking threads. This enables real-time updates with less resource consumption. Use cases include real-time dashboards, collaborative editing tools, notification systems, chat applications, and live monitoring interfaces where servers need to push data to clients as it becomes available without requiring clients to repeatedly poll for updates."
            },
            {
              "title": "Resource-Constrained Environments",
              "description": "In environments with limited resources (like edge devices or containers with restricted memory/CPU), reactive programming can improve efficiency by reducing thread usage and memory consumption compared to thread-per-request models. Many IoT applications, edge computing scenarios, and cloud applications running in constrained container environments benefit from the reduced footprint. This allows more logical services to run on the same hardware or enables applications to run on smaller, less expensive infrastructure."
            }
          ]
        },
        {
          "category": "Advanced",
          "points": [
            {
              "title": "Resilient Communication Patterns",
              "description": "Systems requiring sophisticated resilience patterns (circuit breakers, retries with backoff, fallbacks, bulkheads) benefit from reactive libraries that integrate these patterns. This is particularly valuable in distributed systems where network failures are common. Reactive libraries like Reactor and RxJava integrate well with resilience tools like Resilience4j, allowing systems to gracefully handle intermittent failures, prevent cascading failures, and maintain partial functionality even when dependencies are unavailable. This is critical for high-availability systems in finance, e-commerce, and other mission-critical domains."
            },
            {
              "title": "High-Throughput ETL Processing",
              "description": "Extract, Transform, Load (ETL) workflows that process large volumes of data can use reactive streams to implement backpressure, allowing the system to process data at a sustainable rate, with controlled parallelism and resource usage. This is valuable in data pipelines, batch processing systems, and real-time analytics platforms that need to transform and enrich data continuously without overwhelming downstream systems. The ability to process massive datasets while adapting to varying system capacities makes reactive programming a good fit for modern data engineering applications."
            },
            {
              "title": "Responsive User Interfaces",
              "description": "While most reactive programming in Java focuses on server-side, some Java UI frameworks (JavaFX with ReactFX, Android with RxJava) use reactive patterns to handle user input, application state, and UI updates in a more maintainable way than traditional event listeners. The reactive approach simplifies managing complex UI state transitions, handling user input validation, debouncing user events, and coordinating between different parts of the UI. This leads to more responsive interfaces with cleaner, more maintainable code that can better handle complex workflows and asynchronous operations in user-facing applications."
            },
            {
              "title": "Data Streaming and Complex Event Processing",
              "description": "Applications that need to process streaming data with time-based windowing, aggregations, joins, and pattern detection benefit from reactive programming's operators for advanced stream manipulation. Examples include fraud detection systems, anomaly detection, real-time recommendations, and complex event processing applications that need to identify patterns across multiple event streams. Reactive libraries provide the high-level operators needed to express complex stream processing logic clearly and concisely, making these applications easier to develop and maintain."
            }
          ]
        }
      ],
      "relatedQuestions": [
      ]
    },
    {
      "id": "java-reactive-conversion-core-java-r-12",
      "skillLevel": "basic",
      "shortTitle": "Converting Between Models",
      "question": "How can you effectively convert between reactive and traditional programming models in Java?",
      "answerInsights": [
        {
          "category": "Basic",
          "points": [
            {
              "title": "Blocking to Reactive",
              "description": "To convert blocking operations to reactive, wrap them using `Mono.fromCallable()` or `Flux.defer()` (in Project Reactor) or `Single.fromCallable()` or `Observable.fromCallable()` (in RxJava). Execute these on an appropriate scheduler to avoid blocking the main thread:\n```java\n// Project Reactor example\nMono<User> userMono = Mono.fromCallable(() -> blockingService.getUserById(id))\n    .subscribeOn(Schedulers.boundedElastic());\n\n// RxJava example\nSingle<User> userSingle = Single.fromCallable(() -> blockingService.getUserById(id))\n    .subscribeOn(Schedulers.io());\n```\nThis pattern isolates blocking calls on dedicated thread pools, preserving the non-blocking nature of your reactive application while allowing integration with traditional blocking code."
            },
            {
              "title": "Reactive to Blocking",
              "description": "When you need to integrate reactive code with blocking consumers, use blocking terminal operators like `block()` in Project Reactor or `blockingGet()` in RxJava. Note that this should be avoided in fully reactive applications:\n```java\n// Getting a result synchronously in Reactor\nUser user = userRepository.findById(id) // Returns Mono<User>\n    .block(); // Blocks until the result is available\n\n// Getting a result synchronously in RxJava\nUser user = userRepository.findById(id) // Returns Single<User>\n    .blockingGet(); // Blocks until the result is available\n```\nThese blocking operators should generally only be used at application boundaries (like in command-line tools), tests, or when integrating with legacy systems."
            },
            {
              "title": "Collections to Reactive Streams",
              "description": "Convert standard collections to reactive streams using factory methods:\n```java\n// From a list to a Flux\nList<String> items = Arrays.asList(\"a\", \"b\", \"c\");\nFlux<String> flux = Flux.fromIterable(items);\n\n// From an array to a Flux\nString[] array = new String[] {\"a\", \"b\", \"c\"};\nFlux<String> flux = Flux.fromArray(array);\n\n// From a list to an Observable\nObservable<String> observable = Observable.fromIterable(items);\n\n// From a stream to a Flux\nStream<String> stream = items.stream();\nFlux<String> flux = Flux.fromStream(stream); // Note: streams cannot be reused after consumption\n```\nThese factory methods make it easy to integrate existing collections into a reactive pipeline."
            }
          ]
        },
        {
          "category": "Intermediate",
          "points": [
            {
              "title": "CompletableFuture Integration",
              "description": "Convert between CompletableFuture and reactive types:\n```java\n// CompletableFuture to Mono\nCompletableFuture<String> future = service.getDataAsync();\nMono<String> mono = Mono.fromFuture(future);\n\n// Mono to CompletableFuture\nCompletableFuture<String> newFuture = mono.toFuture();\n\n// CompletableFuture to Single\nSingle<String> single = Single.fromFuture(future);\n\n// Multiple CompletableFutures to Flux\nList<CompletableFuture<String>> futures = List.of(\n    service.getDataAsync(\"A\"),\n    service.getDataAsync(\"B\"),\n    service.getDataAsync(\"C\")\n);\nFlux<String> flux = Flux.fromIterable(futures)\n    .flatMap(f -> Mono.fromFuture(f));\n```\nThis seamless integration with CompletableFuture allows you to compose existing asynchronous code with reactive pipelines."
            },
            {
              "title": "Callbacks to Reactive",
              "description": "Convert callback-based APIs to reactive streams using create operators:\n```java\n// Converting a callback-based API to a Mono\nMono<Response> mono = Mono.create(sink -> {\n    client.executeRequest(request, new Callback<Response>() {\n        @Override\n        public void onSuccess(Response response) {\n            sink.success(response);\n        }\n        \n        @Override\n        public void onError(Throwable error) {\n            sink.error(error);\n        }\n    });\n});\n\n// Converting event listeners to Flux\nFlux<MouseEvent> mouseClicks = Flux.create(sink -> {\n    MouseListener listener = new MouseListener() {\n        @Override\n        public void mouseClicked(MouseEvent e) {\n            sink.next(e);\n        }\n        \n        // Other required methods...\n    };\n    \n    component.addMouseListener(listener);\n    \n    // Clean up when the subscription is cancelled\n    sink.onDispose(() -> component.removeMouseListener(listener));\n});\n```\nThis approach transforms callback-based APIs to reactive streams, making them composable and easier to work with."
            },
            {
              "title": "Stream API Integration",
              "description": "Convert between Java Stream API and reactive streams:\n```java\n// From Stream to Flux\nStream<String> stream = Arrays.asList(\"a\", \"b\", \"c\").stream();\nFlux<String> flux = Flux.fromStream(stream);\n\n// From Flux to Stream (be careful with infinite streams)\nStream<String> newStream = flux.toStream(); // Blocks!\n\n// Stream operations with reactive collections\nFlux<Integer> numbers = Flux.range(1, 100);\nFlux<Integer> processed = numbers\n    .collectList()\n    .map(list -> list.stream()\n        .filter(n -> n % 2 == 0)\n        .map(n -> n * n)\n        .collect(Collectors.toList()))\n    .flatMapMany(Flux::fromIterable);\n```\nWhile both Stream API and reactive streams enable functional-style programming, Stream API is blocking and built for data processing, while reactive streams are asynchronous and built for event handling."
            }
          ]
        },
        {
          "category": "Advanced",
          "points": [
            {
              "title": "Integrating with ExecutorService",
              "description": "Customize thread allocation when converting blocking to reactive:\n```java\n// Using a custom executor with Project Reactor\nExecutorService executor = Executors.newFixedThreadPool(10);\nScheduler scheduler = Schedulers.fromExecutor(executor);\n\nMono.fromCallable(() -> blockingService.getData())\n    .subscribeOn(scheduler);\n\n// Using a custom executor with RxJava\nExecutorService executor = Executors.newFixedThreadPool(10);\nScheduler scheduler = Schedulers.from(executor);\n\nSingle.fromCallable(() -> blockingService.getData())\n    .subscribeOn(scheduler);\n\n// Properly managing executor lifecycle\npublic class CustomSchedulerProvider implements DisposableBean {\n    private final ExecutorService executor;\n    private final Scheduler scheduler;\n    \n    public CustomSchedulerProvider() {\n        this.executor = Executors.newFixedThreadPool(10, \n            new ThreadFactoryBuilder().setNameFormat(\"blocking-pool-%d\").build());\n        this.scheduler = Schedulers.fromExecutor(executor);\n    }\n    \n    public Scheduler getScheduler() {\n        return scheduler;\n    }\n    \n    @Override\n    public void destroy() {\n        executor.shutdown();\n    }\n}\n```\nThis approach gives you fine-grained control over the threading model used for executing blocking code in a reactive context."
            },
            {
              "title": "Rx to Reactor Conversion",
              "description": "Convert between RxJava and Project Reactor using adapters and the Reactive Streams interfaces:\n```java\n// RxJava to Reactor\nimport io.reactivex.rxjava3.core.Flowable;\nimport reactor.core.publisher.Flux;\n\nFlowable<String> flowable = Flowable.just(\"a\", \"b\", \"c\");\nFlux<String> flux = Flux.from(flowable); // Uses Reactive Streams\n\n// Reactor to RxJava\nFlux<String> flux = Flux.just(\"a\", \"b\", \"c\");\nFlowable<String> flowable = Flowable.fromPublisher(flux);\n\n// More complex conversions\nSingle<User> single = rxUserService.getUser(id);\nMono<User> mono = Mono.from(single.toFlowable());\n\nMono<Order> mono = reactorOrderService.getOrder(id);\nSingle<Order> single = Single.fromPublisher(mono);\n```\nThis interoperability is made possible by the shared Reactive Streams interfaces, allowing libraries to work together seamlessly."
            },
            {
              "title": "Advanced Integration Patterns",
              "description": "When integrating reactive code into a larger traditional application, consider these patterns:\n\n1. **Reactive Core, Blocking Boundaries**: Keep your core logic reactive but convert to blocking at the edges when interfacing with traditional systems.\n\n2. **Adaptive Concurrency**: Use dynamic thread pool sizing to adapt to varying workloads:\n```java\nAdaptiveThreadPoolExecutor executor = new AdaptiveThreadPoolExecutor(\n    4,    // core pool size\n    20,   // max pool size\n    60L,  // keep alive time\n    TimeUnit.SECONDS,\n    new ArrayBlockingQueue<>(1000),\n    new ThreadPoolExecutor.CallerRunsPolicy());\n```\n\n3. **Hybrid Processing Model**: Combine a main reactive flow with isolated blocking operations:\n```java\n// Main reactive flow with isolated blocking sections\nFlux<Document> documents = Flux.fromIterable(documentIds)\n    .flatMap(id -> Mono.fromCallable(() -> blockingDbAccess.getDocumentMetadata(id))\n        .subscribeOn(Schedulers.boundedElastic())\n        .flatMap(meta -> {\n            if (meta.needsHeavyProcessing()) {\n                return Mono.fromCallable(() -> blockingProcessor.process(meta))\n                    .subscribeOn(Schedulers.boundedElastic());\n            } else {\n                return Mono.just(meta).map(this::lightProcessing);\n            }\n        }));\n```\n\nThese patterns help you achieve a smooth migration from traditional to reactive programming while maximizing the benefits of both approaches."
            },
            {
              "title": "Mixing Synchronous and Asynchronous Code",
              "description": "When integrating reactive code into a larger traditional application, consider using \"islands of reactivity\": keeping subsystems internal components fully reactive, while offering synchronous APIs at their boundaries. This pattern works well when incrementally adopting reactive programming in an existing codebase, allowing gradual migration while maintaining backward compatibility with existing code.\n\n```java\n// Reactive implementation with blocking API\npublic class UserServiceAdapter {\n    private final ReactiveUserRepository reactiveRepository;\n    \n    // Traditional blocking API\n    public User getUserById(String id) {\n        return reactiveRepository.findById(id)\n            .block(Duration.ofSeconds(5)); // Convert to blocking with timeout\n    }\n    \n    // Reactive API for reactive clients\n    public Mono<User> getUserByIdReactive(String id) {\n        return reactiveRepository.findById(id);\n    }\n    \n    // Hybrid method - blocking call with reactive internals for better resource usage\n    public List<User> getActiveUsers() {\n        return reactiveRepository.findByStatus(Status.ACTIVE)\n            .collectList()\n            .block(Duration.ofSeconds(10));\n    }\n}\n```"
            }
          ]
        }
      ],
      "relatedQuestions": [
        "java-reactive-streams-core-java-r-1"
      ]
    },
    {
      "id": "java-reactive-spring-webflux-core-java-r-13",
      "skillLevel": "basic",
      "shortTitle": "Spring WebFlux Basics",
      "question": "How does Spring WebFlux enable reactive programming for web applications in Java?",
      "answerInsights": [
        {
          "category": "Basic",
          "points": [
            {
              "title": "Overview",
              "description": "**Spring WebFlux** is a reactive web framework that provides an alternative to Spring MVC for building non-blocking, reactive web applications. It's built on Project Reactor and supports both functional and annotation-based programming models. WebFlux is part of the broader Spring ecosystem but is designed specifically for reactive, non-blocking applications that can handle a large number of concurrent connections with fewer resources than traditional servlet-based applications."
            },
            {
              "title": "Non-blocking Runtime",
              "description": "Unlike Spring MVC which uses a thread-per-request model, WebFlux runs on servers that use a non-blocking event loop model (like Netty, Undertow, or Servlet 3.1+ containers). This enables handling many more concurrent connections with fewer threads. The event loop model means a small number of threads can handle many requests concurrently by efficiently managing I/O operations, leading to better resource utilization, especially when applications make I/O-bound calls to databases or external services."
            },
            {
              "title": "Reactive Controllers",
              "description": "WebFlux controllers return reactive types (Mono/Flux) instead of direct values:\n```java\n@RestController\npublic class UserController {\n    private final UserRepository userRepository;\n    \n    // Constructor injection\n    public UserController(UserRepository userRepository) {\n        this.userRepository = userRepository;\n    }\n    \n    @GetMapping(\"/users/{id}\")\n    public Mono<User> getUser(@PathVariable String id) {\n        return userRepository.findById(id);\n    }\n    \n    @GetMapping(\"/users\")\n    public Flux<User> getAllUsers() {\n        return userRepository.findAll();\n    }\n    \n    @PostMapping(\"/users\")\n    public Mono<ResponseEntity<User>> createUser(@RequestBody Mono<User> userMono) {\n        return userMono\n            .flatMap(userRepository::save)\n            .map(user -> ResponseEntity.created(URI.create(\"/users/\" + user.getId()))\n                .body(user));\n    }\n}\n```\nThese reactive return types enable end-to-end non-blocking request processing, allowing WebFlux to handle many concurrent requests efficiently."
            }
          ]
        },
        {
          "category": "Intermediate",
          "points": [
            {
              "title": "Functional Routes",
              "description": "In addition to annotated controllers, WebFlux supports a functional programming model with RouterFunctions:\n```java\n@Configuration\npublic class UserRoutes {\n    @Bean\n    public RouterFunction<ServerResponse> userRoutes(UserHandler userHandler) {\n        return route()\n            .path(\"/users\", builder -> builder\n                .GET(\"/{id}\", userHandler::getUser)\n                .GET(\"\", userHandler::getAllUsers)\n                .POST(\"\", userHandler::createUser)\n                .PUT(\"/{id}\", userHandler::updateUser)\n                .DELETE(\"/{id}\", userHandler::deleteUser))\n            .build();\n    }\n}\n\n// Corresponding handler class\n@Component\npublic class UserHandler {\n    private final UserRepository userRepository;\n    \n    // Constructor injection\n    public UserHandler(UserRepository userRepository) {\n        this.userRepository = userRepository;\n    }\n    \n    public Mono<ServerResponse> getUser(ServerRequest request) {\n        String id = request.pathVariable(\"id\");\n        return userRepository.findById(id)\n            .flatMap(user -> ServerResponse.ok()\n                .contentType(MediaType.APPLICATION_JSON)\n                .bodyValue(user))\n            .switchIfEmpty(ServerResponse.notFound().build());\n    }\n    \n    public Mono<ServerResponse> getAllUsers(ServerRequest request) {\n        return ServerResponse.ok()\n            .contentType(MediaType.APPLICATION_JSON)\n            .body(userRepository.findAll(), User.class);\n    }\n    \n    // Other handler methods\n}\n```\nThis functional style provides a more declarative way to define routes and handlers, with better composition and reuse capabilities compared to annotation-based controllers."
            },
            {
              "title": "WebClient",
              "description": "WebFlux includes **WebClient**, a reactive HTTP client that replaces RestTemplate:\n```java\nWebClient client = WebClient.create(\"https://api.example.com\");\n\n// Making a request\nMono<User> user = client.get()\n    .uri(\"/users/{id}\", userId)\n    .retrieve()\n    .bodyToMono(User.class);\n    \n// Making parallel requests\nFlux<User> users = Flux.fromIterable(userIds)\n    .flatMap(id -> client.get()\n        .uri(\"/users/{id}\", id)\n        .retrieve()\n        .bodyToMono(User.class),\n        10); // Limiting concurrency to 10 parallel requests\n        \n// Advanced request with headers, error handling, and exchange\nMono<User> user = client.post()\n    .uri(\"/users\")\n    .contentType(MediaType.APPLICATION_JSON)\n    .header(\"X-API-Key\", apiKey)\n    .bodyValue(new UserCreateRequest(\"John Doe\", \"john@example.com\"))\n    .retrieve()\n    .onStatus(HttpStatus::is4xxClientError, response ->\n        Mono.error(new ClientException(\"Invalid request: \" + response.statusCode())))\n    .onStatus(HttpStatus::is5xxServerError, response ->\n        Mono.error(new ServerException(\"Server error: \" + response.statusCode())))\n    .bodyToMono(User.class);\n```\nWebClient provides a fully reactive way to make HTTP requests, with backpressure support and non-blocking I/O."
            },
            {
              "title": "Reactive Data Access",
              "description": "Spring Data provides reactive extensions for MongoDB, Redis, Cassandra, and R2DBC (Reactive Relational Database Connectivity) with repositories returning Mono/Flux:\n```java\n// MongoDB reactive repository example\npublic interface UserRepository extends ReactiveMongoRepository<User, String> {\n    Flux<User> findByLastName(String lastName);\n    Mono<User> findByEmail(String email);\n    Flux<User> findByAgeBetween(int minAge, int maxAge);\n    \n    @Query(\"{status: ?0}\")\n    Flux<User> findByStatus(UserStatus status);\n}\n\n// R2DBC reactive SQL repository example\npublic interface OrderRepository extends ReactiveCrudRepository<Order, Long> {\n    @Query(\"SELECT * FROM orders WHERE customer_id = :customerId\")\n    Flux<Order> findByCustomerId(String customerId);\n    \n    Mono<Long> countByStatus(OrderStatus status);\n    \n    // Custom implementation example with R2dbcEntityTemplate\n    default Flux<Order> findRecentOrdersByCustomer(String customerId, int limit) {\n        return entityTemplate.select(Order.class)\n            .matching(Query.query(Criteria.where(\"customerId\").is(customerId))\n                          .sort(Sort.by(\"createdDate\").descending())\n                          .limit(limit))\n            .all();\n    }\n}\n```\nThese reactive repositories complete the end-to-end reactive pipeline from database to web layer, ensuring that applications remain non-blocking throughout."
            }
          ]
        },
        {
          "category": "Advanced",
          "points": [
            {
              "title": "Server-Sent Events",
              "description": "WebFlux supports Server-Sent Events (SSE) for pushing updates to clients, perfect for real-time dashboards, notifications, or activity feeds:\n```java\n@GetMapping(value = \"/events\", produces = MediaType.TEXT_EVENT_STREAM_VALUE)\npublic Flux<ServerSentEvent<Event>> streamEvents() {\n    return eventService.getEventStream()\n        .map(event -> ServerSentEvent.builder(event)\n            .id(event.getId())\n            .event(\"update\")\n            .build());\n}\n\n// Creating a stream of events with interval\n@GetMapping(value = \"/stock-prices\", produces = MediaType.TEXT_EVENT_STREAM_VALUE)\npublic Flux<StockPrice> streamStockPrices() {\n    return Flux.interval(Duration.ofSeconds(1))\n        .map(tick -> stockService.getCurrentPrice())\n        .share(); // Share the source among multiple subscribers\n}\n\n// Combining multiple event sources\n@GetMapping(value = \"/dashboard-data\", produces = MediaType.TEXT_EVENT_STREAM_VALUE)\npublic Flux<DashboardUpdate> streamDashboardData() {\n    Flux<UserActivity> userActivity = userActivityService.streamActivity();\n    Flux<SystemMetric> systemMetrics = monitoringService.streamMetrics();\n    Flux<Alert> alerts = alertService.streamAlerts();\n    \n    return Flux.merge(userActivity, systemMetrics, alerts)\n        .map(event -> DashboardUpdate.fromEvent(event));\n}\n```\nSSE enables efficient server-to-client streaming for real-time applications, keeping connections open and efficiently using server resources."
            },
            {
              "title": "WebSockets",
              "description": "WebFlux includes reactive WebSocket support for bidirectional communication:\n```java\n@Configuration\npublic class WebSocketConfig {\n    @Bean\n    public HandlerMapping webSocketMapping() {\n        Map<String, WebSocketHandler> handlers = new HashMap<>();\n        handlers.put(\"/ws/chat\", new ReactiveWebSocketHandler());\n        \n        SimpleUrlHandlerMapping mapping = new SimpleUrlHandlerMapping();\n        mapping.setUrlMap(handlers);\n        mapping.setOrder(-1); // Higher precedence than HTTP handlers\n        return mapping;\n    }\n}\n\npublic class ReactiveWebSocketHandler implements WebSocketHandler {\n    private final Sinks.Many<String> chatMessageSink = Sinks.many().multicast().onBackpressureBuffer();\n    private final Flux<String> chatMessages = chatMessageSink.asFlux();\n    \n    @Override\n    public Mono<Void> handle(WebSocketSession session) {\n        // Handle incoming messages\n        Mono<Void> input = session.receive()\n            .map(WebSocketMessage::getPayloadAsText)\n            .doOnNext(message -> {\n                // Broadcast message to all sessions\n                chatMessageSink.tryEmitNext(message);\n            })\n            .then();\n            \n        // Send outgoing messages\n        Mono<Void> output = session.send(\n            chatMessages.map(session::textMessage)\n        );\n        \n        // Combine both operations\n        return Mono.zip(input, output).then();\n    }\n}\n```\nWebSocket support enables full-duplex communication for applications needing real-time, low-latency interactions like chat, gaming, or collaborative editing."
            },
            {
              "title": "Security Integration",
              "description": "Spring Security integrates with WebFlux, providing reactive authentication and authorization:\n```java\n@Configuration\n@EnableWebFluxSecurity\npublic class SecurityConfig {\n    @Bean\n    public SecurityWebFilterChain securityWebFilterChain(ServerHttpSecurity http) {\n        return http\n            .authorizeExchange()\n                .pathMatchers(\"/public/**\").permitAll()\n                .pathMatchers(\"/api/admin/**\").hasRole(\"ADMIN\")\n                .pathMatchers(\"/api/**\").authenticated()\n                .anyExchange().authenticated()\n            .and()\n            .oauth2ResourceServer()\n                .jwt()\n            .and()\n            .csrf().disable() // For API endpoints\n            .build();\n    }\n    \n    @Bean\n    public ReactiveUserDetailsService userDetailsService() {\n        UserDetails user = User.withDefaultPasswordEncoder()\n            .username(\"user\")\n            .password(\"password\")\n            .roles(\"USER\")\n            .build();\n        \n        UserDetails admin = User.withDefaultPasswordEncoder()\n            .username(\"admin\")\n            .password(\"password\")\n            .roles(\"ADMIN\")\n            .build();\n        \n        return new MapReactiveUserDetailsService(user, admin);\n    }\n    \n    // For reactive JWT authentication\n    @Bean\n    public ReactiveJwtDecoder jwtDecoder() {\n        return ReactiveJwtDecoders.fromIssuerLocation(\"https://auth.example.com\");\n    }\n}\n```\nSpring Security for WebFlux provides reactive implementations of security filters, authentication managers, and authorization mechanisms, ensuring security operations don't block the reactive pipeline."
            },
            {
              "title": "Reactive Testing",
              "description": "Spring WebFlux provides extensive testing support through WebTestClient:\n```java\n@WebFluxTest(UserController.class)\npublic class UserControllerTest {\n    @Autowired\n    private WebTestClient webTestClient;\n    \n    @MockBean\n    private UserRepository userRepository;\n    \n    @Test\n    void testGetUser() {\n        User user = new User(\"1\", \"Test User\", \"test@example.com\");\n        when(userRepository.findById(\"1\")).thenReturn(Mono.just(user));\n        \n        webTestClient.get()\n            .uri(\"/users/{id}\", \"1\")\n            .exchange()\n            .expectStatus().isOk()\n            .expectHeader().contentType(MediaType.APPLICATION_JSON)\n            .expectBody(User.class)\n            .isEqualTo(user);\n    }\n    \n    @Test\n    void testGetAllUsers() {\n        User user1 = new User(\"1\", \"User 1\", \"user1@example.com\");\n        User user2 = new User(\"2\", \"User 2\", \"user2@example.com\");\n        \n        when(userRepository.findAll()).thenReturn(Flux.just(user1, user2));\n        \n        webTestClient.get()\n            .uri(\"/users\")\n            .exchange()\n            .expectStatus().isOk()\n            .expectHeader().contentType(MediaType.APPLICATION_JSON)\n            .expectBodyList(User.class)\n            .hasSize(2)\n            .contains(user1, user2);\n    }\n    \n    @Test\n    void testStreamEvents() {\n        Event event1 = new Event(\"1\", \"Event 1\", LocalDateTime.now());\n        Event event2 = new Event(\"2\", \"Event 2\", LocalDateTime.now());\n        \n        when(eventService.getEventStream()).thenReturn(Flux.just(event1, event2));\n        \n        webTestClient.get()\n            .uri(\"/events\")\n            .accept(MediaType.TEXT_EVENT_STREAM)\n            .exchange()\n            .expectStatus().isOk()\n            .expectHeader().contentType(MediaType.TEXT_EVENT_STREAM_VALUE)\n            .returnResult(Event.class)\n            .getResponseBody()\n            .as(StepVerifier::create)\n            .expectNext(event1, event2)\n            .verifyComplete();\n    }\n}\n```\nThis comprehensive testing support ensures you can test reactive web applications effectively without relying on blocking operations during tests."
            }
          ]
        }
      ],
      "relatedQuestions": [
        "java-project-reactor-core-java-r-4"
      ]
    },
    {
      "id": "java-reactive-hot-cold-core-java-r-14",
      "skillLevel": "basic",
      "shortTitle": "Hot vs Cold Publishers",
      "question": "What's the difference between hot and cold publishers in reactive programming, and when would you use each?",
      "answerInsights": [
        {
          "category": "Basic",
          "points": [
            {
              "title": "Cold Publishers",
              "description": "**Cold publishers** start producing data when a subscriber subscribes and produce a fresh data sequence for each subscriber. They're like DVDs—each viewer watches from the beginning. Examples include: `Flux.range()`, `Mono.fromCallable()`, HTTP requests with WebClient, or database queries. Cold publishers are lazy, only executing their data pipeline when subscribed to, and they provide the complete data set to each subscriber independently. This behavior is ideal for operations that can be repeated without side effects, such as data fetching or calculation."
            },
            {
              "title": "Hot Publishers",
              "description": "**Hot publishers** emit data regardless of subscriptions, and new subscribers only receive data emitted after they subscribe. They're like live TV broadcasts—viewers tune in and see only what's broadcast from that point forward. Examples include UI events, system metrics, or real-time data feeds. Hot publishers are typically active before any subscribers arrive and represent ongoing streams of events or updates. Subscribers joining at different times will receive different subsets of the data, based on when they subscribe."
            },
            {
              "title": "Basic Usage Patterns",
              "description": "Use **cold publishers** when each subscriber needs its own complete data set (e.g., database queries or HTTP calls). Use **hot publishers** when sharing a single data stream among multiple subscribers (e.g., mouse clicks or stock price updates). These characteristics directly affect how your application behaves:\n\n```java\n// Cold publisher example - each subscriber triggers a new database query\nFlux<User> userFlux = Flux.defer(() -> repository.findAllUsers());\n\n// First subscriber causes query execution\nuserFlux.subscribe(user -> logger.info(\"Subscriber 1: {}\", user));\n\n// Second subscriber causes another query execution\nuserFlux.subscribe(user -> logger.info(\"Subscriber 2: {}\", user));\n\n// Hot publisher example - all subscribers share one event stream\nSinks.Many<StockUpdate> stockSink = Sinks.many().multicast().onBackpressureBuffer();\nFlux<StockUpdate> stockUpdates = stockSink.asFlux();\n\n// First subscriber starts receiving updates from now\nstockUpdates.subscribe(update -> logger.info(\"Trader 1: {}\", update));\n\n// Emit events to all current subscribers\nstockSink.tryEmitNext(new StockUpdate(\"AAPL\", 150.25));\n\n// Second subscriber only sees events from this point forward\nstockUpdates.subscribe(update -> logger.info(\"Trader 2: {}\", update));\n\nstockSink.tryEmitNext(new StockUpdate(\"AAPL\", 151.30)); // Both subscribers receive this\n```"
            }
          ]
        },
        {
          "category": "Intermediate",
          "points": [
            {
              "title": "Converting Cold to Hot",
              "description": "You can convert a cold publisher to hot using operators like `share()`, `publish()`, or `cache()` in Project Reactor:\n```java\n// Cold publisher\nFlux<Integer> cold = Flux.range(1, 10)\n    .delayElements(Duration.ofMillis(100))\n    .doOnSubscribe(s -> logger.info(\"New subscription\"))\n    .doOnNext(i -> logger.info(\"Emitting {}\", i));\n\n// Convert to hot with share() - multicasts to all subscribers\nFlux<Integer> hot = cold.share();\n\n// First subscriber gets all values\nDisposable sub1 = hot.subscribe(i -> logger.info(\"First: {}\", i));\n\n// Delay before second subscription\nThread.sleep(500); // After ~5 elements have been emitted\n\n// Second subscriber only gets remaining values\nDisposable sub2 = hot.subscribe(i -> logger.info(\"Second: {}\", i)); // Only sees ~6-10\n\n// With publish() and connect() for more control\nConnectableFlux<Long> hotFlux = Flux.interval(Duration.ofMillis(100))\n    .publish();\n\n// Add subscribers before connection\nhotFlux.subscribe(i -> logger.info(\"First: {}\", i));\nhotFlux.subscribe(i -> logger.info(\"Second: {}\", i));\n\n// Nothing happens until connect is called\nDisposable connection = hotFlux.connect(); // Both subscribers start receiving data\n\n// Later we can cancel the connection\nconnection.dispose();\n```\nThese operators transform cold publishers to hot, allowing multiple subscribers to share a single execution of the source publisher, which can save resources for expensive operations."
            },
            {
              "title": "Replay and Caching",
              "description": "Some hot publishers can replay emissions to new subscribers:\n```java\n// Cache entire history and replay to new subscribers\nFlux<Integer> cached = Flux.range(1, 10)\n    .delayElements(Duration.ofMillis(100))\n    .cache(); // Will replay all items to new subscribers\n\n// First subscriber triggers the source\nDisposable sub1 = cached.subscribe(i -> logger.info(\"First: {}\", i));\n\n// Wait for completion\nThread.sleep(1500);\n\n// Second subscriber gets all cached values immediately\nDisposable sub2 = cached.subscribe(i -> logger.info(\"Second: {}\", i));\n\n// Replay only last N elements\nFlux<Integer> replayLast = Flux.range(1, 10)\n    .delayElements(Duration.ofMillis(100))\n    .replay(3) // Keep last 3 values for replay\n    .autoConnect();\n\n// Time-based caching\nFlux<StockPrice> stockPrices = stockPriceSource\n    .cache(Duration.ofMinutes(5)); // Cache values for 5 minutes\n```\nReplay capabilities allow new subscribers to catch up on recent emissions, which is useful for ensuring consistent state across components that might subscribe at different times."
            },
            {
              "title": "Multicast with ConnectableFlux",
              "description": "Fine-grained control over when emissions start using `publish()` and `connect()`:\n```java\n// Create a connectable flux that won't emit until connect is called\nConnectableFlux<Integer> published = Flux.range(1, 5)\n    .delayElements(Duration.ofMillis(100))\n    .publish();\n\n// Set up subscribers\npublished.subscribe(i -> logger.info(\"First: {}\", i));\npublished.subscribe(i -> logger.info(\"Second: {}\", i));\n\n// Nothing happens until we call connect\nDisposable connection = published.connect(); // Now both subscribers receive the same emissions\n\n// Auto-connect after N subscribers\nFlux<Long> autoConnected = Flux.interval(Duration.ofSeconds(1))\n    .publish()\n    .autoConnect(2); // Automatically connects when 2 subscribers arrive\n\n// First subscriber connects but nothing happens yet\nautoConnected.subscribe(i -> logger.info(\"First: {}\", i));\n\n// Second subscriber triggers the connection\nautoConnected.subscribe(i -> logger.info(\"Second: {}\", i)); // Now emissions start\n\n// Reference counting with refCount\nFlux<Long> refCounted = Flux.interval(Duration.ofSeconds(1))\n    .publish()\n    .refCount(2); // Connect when 2 subscribers arrive, disconnect when all leave\n```\nConnectable publishers give you precise control over when the source publisher begins emitting items, which is useful for ensuring all subscribers are ready before data starts flowing."
            }
          ]
        },
        {
          "category": "Advanced",
          "points": [
            {
              "title": "Resource Management",
              "description": "Hot publishers need careful resource management since they may be producing data even without active subscribers. Use `autoConnect(n)` or `refCount(n)` to automatically connect when reaching n subscribers and to disconnect when subscribers leave:\n```java\n// Connect when 2 subscribers arrive, disconnect when all leave\nFlux<Long> shared = Flux.interval(Duration.ofSeconds(1))\n    .publish()\n    .refCount(2); // Connects at 2 subscribers, disconnects at 0\n\n// Keep connection for grace period after last subscriber leaves\nFlux<Long> gracePeriod = Flux.interval(Duration.ofSeconds(1))\n    .publish()\n    .refCount(1, Duration.ofSeconds(10)); // Disconnect 10 seconds after last subscriber\n\n// Auto-disconnect and reconnect\npublic Flux<Data> createReconnectingFlux() {\n    return Flux.defer(() -> {\n            logger.info(\"Connecting to data source\");\n            return dataSource.connect();\n        })\n        .doFinally(signal -> logger.info(\"Disconnected from data source\"))\n        .publish()\n        .refCount(1);\n}\n```\nProper resource management ensures that hot publishers don't waste resources when not needed while remaining available when subscribers are present."
            },
            {
              "title": "Real-world Hot Sources",
              "description": "Common hot publishers include event buses, message brokers, and reactive wrappers for system events. Creating custom hot sources often involves `DirectProcessor`, `EmitterProcessor`, or `Sinks` in Reactor, or `Subject`s in RxJava:\n```java\n// Creating a hot source with a sink in Reactor\nSinks.Many<String> sink = Sinks.many().multicast().onBackpressureBuffer();\nFlux<String> hotFlux = sink.asFlux();\n\n// Event bus implementation with hot publisher\npublic class ReactiveEventBus {\n    private final Sinks.Many<Event> sink = Sinks.many().multicast().onBackpressureBuffer();\n    private final Flux<Event> events = sink.asFlux();\n    \n    public void publish(Event event) {\n        sink.tryEmitNext(event)\n            .orThrow(); // Handle emission failure\n    }\n    \n    public Flux<Event> subscribe() {\n        return events;\n    }\n    \n    public Flux<Event> subscribe(EventType type) {\n        return events.filter(event -> event.getType() == type);\n    }\n}\n\n// Message queue adapter using RxJava\npublic class RxKafkaConsumer<K, V> {\n    private final Subject<ConsumerRecord<K, V>> subject = PublishSubject.<ConsumerRecord<K, V>>create().toSerialized();\n    \n    public RxKafkaConsumer(String topic, Properties props) {\n        KafkaConsumer<K, V> consumer = new KafkaConsumer<>(props);\n        consumer.subscribe(Collections.singletonList(topic));\n        \n        // Start polling in a separate thread\n        Executors.newSingleThreadExecutor().submit(() -> {\n            while (!Thread.currentThread().isInterrupted()) {\n                ConsumerRecords<K, V> records = consumer.poll(Duration.ofMillis(100));\n                for (ConsumerRecord<K, V> record : records) {\n                    subject.onNext(record);\n                }\n            }\n        });\n    }\n    \n    public Observable<ConsumerRecord<K, V>> observe() {\n        return subject;\n    }\n}\n```\nThese implementations demonstrate how to create hot publishers for different use cases like event buses or message queue integration."
            },
            {
              "title": "Testing Considerations",
              "description": "Testing hot and cold publishers requires different approaches:\n- Cold publishers are easier to test since each test gets a fresh data stream\n- Hot publishers often need special handling for testing, such as subscribing before triggering events or using `TestPublisher` in Reactor\n- Time-based tests for hot publishers benefit from virtual time schedulers to control emissions\n\n```java\n// Testing a cold publisher\n@Test\nvoid testColdPublisher() {\n    Flux<Integer> cold = service.getData(); // Cold publisher\n    \n    // Simple verification\n    StepVerifier.create(cold)\n        .expectNext(1, 2, 3, 4, 5)\n        .verifyComplete();\n    \n    // Another test gets a fresh stream\n    StepVerifier.create(cold)\n        .expectNext(1, 2, 3, 4, 5)\n        .verifyComplete();\n}\n\n// Testing a hot publisher\n@Test\nvoid testHotPublisher() {\n    // Create controlled test publisher\n    TestPublisher<String> testPublisher = TestPublisher.create();\n    Flux<String> hot = testPublisher.flux().share();\n    \n    // Set up verification before emitting\n    StepVerifier<String> verifier = StepVerifier.create(hot)\n        .expectNext(\"A\", \"B\", \"C\")\n        .thenCancel()\n        .verifyLater(); // Important: don't verify yet\n    \n    // Emit test data\n    testPublisher.next(\"A\", \"B\", \"C\");\n    \n    // Now trigger verification\n    verifier.verify();\n}\n```\nUnderstanding these testing differences ensures you can properly test both hot and cold publishers in your applications."
            },
            {
              "title": "Hybrid Patterns",
              "description": "Some advanced use cases call for hybrid approaches that combine hot and cold publisher behaviors:\n\n1. **Cache with Time-To-Live**: Caching that expires after a certain period\n```java\npublic <T> Flux<T> cachingFlux(Flux<T> source, Duration ttl) {\n    return Flux.defer(() -> {\n        // Check if cache is valid\n        if (cacheTimestamp.get() != null && \n            Duration.between(cacheTimestamp.get(), Instant.now()).compareTo(ttl) < 0) {\n            return cachedFlux;\n        }\n        \n        // Update cache\n        Flux<T> newCache = source.cache();\n        cachedFlux = newCache;\n        cacheTimestamp.set(Instant.now());\n        return newCache;\n    });\n}\n```\n\n2. **Lazy Hot Publishers**: Hot publishers that only activate when first subscribed to\n```java\nprivate final Flux<MarketData> marketDataStream = Flux.defer(() -> {\n    logger.info(\"Creating market data stream\");\n    return createMarketDataStream().share();\n}).repeat(); // If the source completes, recreate it\n```\n\n3. **Window Caching**: Keep only the last N seconds of data\n```java\npublic Flux<StockTick> getRecentTicks(String symbol) {\n    return stockTickStream\n        .filter(tick -> tick.getSymbol().equals(symbol))\n        .elapsed() // Add timestamps\n        .window(Duration.ofMinutes(5))\n        .flatMap(window -> window.collectList())\n        .map(list -> list.stream()\n            .filter(tuple -> Duration.ofMillis(System.currentTimeMillis() - tuple.getT1())\n                .compareTo(Duration.ofMinutes(5)) <= 0)\n            .map(Tuple2::getT2)\n            .collect(Collectors.toList()))\n        .flatMapIterable(list -> list);\n}\n```\nThese hybrid patterns show how to combine hot and cold publisher characteristics to address complex requirements."
            }
          ]
        }
      ],
      "relatedQuestions": [
        "java-reactive-streams-core-java-r-1"
      ]
    },
    {
      "id": "java-reactive-debugging-core-java-r-15",
      "skillLevel": "intermediate",
      "shortTitle": "Debugging Reactive Code",
      "question": "What techniques and tools can help effectively debug reactive code in Java?",
      "answerInsights": [
        {
          "category": "Basic",
          "points": [
            {
              "title": "Debug Operators",
              "description": "Reactive libraries provide operators to peek into the stream for debugging: `doOnNext`, `doOnError`, `doOnComplete`, etc. These allow observing the stream without changing its content:\n```java\nFlux.range(1, 10)\n    .map(i -> i * 2)\n    .doOnNext(i -> System.out.println(\"After map: \" + i)) // Debug point\n    .filter(i -> i > 5)\n    .doOnNext(i -> System.out.println(\"After filter: \" + i)) // Debug point\n    .subscribe();\n```\nThese operators are fundamental debugging tools, as they let you inspect what's happening at various points in your reactive pipeline without altering the data flow. You can add multiple debug points to track values as they progress through transformations."
            },
            {
              "title": "Logging",
              "description": "Dedicated logging operators simplify adding logs throughout the reactive chain:\n```java\n// Project Reactor\nimport reactor.core.publisher.Flux;\nimport reactor.util.Logger;\nimport reactor.util.Loggers;\n\nLogger log = Loggers.getLogger(MyClass.class);\n\nFlux.range(1, 5)\n    .log(log, Level.INFO, SignalType.ON_NEXT)\n    .map(i -> i * 2)\n    .log(\"afterMap\")    // Built-in prefix\n    .filter(i -> i > 5)\n    .log(log, \"afterFilter\") // Custom logger with prefix\n    .subscribe();\n\n// RxJava\nObservable.range(1, 5)\n    .doOnNext(i -> Log.d(TAG, \"Emitted: \" + i))\n    .map(i -> i * 2)\n    .doOnNext(i -> Log.d(TAG, \"Mapped: \" + i))\n    .subscribe(i -> {}, error -> Log.e(TAG, \"Error: \" + error));\n    \n// Structured logging with MDC\nFlux.range(1, 5)\n    .doOnNext(i -> {\n        MDC.put(\"item\", String.valueOf(i));\n        log.info(\"Processing item\");\n        MDC.remove(\"item\");\n    })\n    .subscribe();\n```\nConsistent logging is especially important in reactive applications since the execution flow isn't linear and may span multiple threads."
            },
            {
              "title": "Stack Trace Debugging",
              "description": "Reactive stack traces can be difficult to interpret because they span asynchronous boundaries. Looking for your application code among framework classes is key. Start at the error point and look for your package names in the stack trace. When debugging reactive code, you'll often see deep stack traces with internal operators from the reactive library. Focus on frames from your application packages and understand that the asynchronous nature means the stack trace might not show the full chain of method calls that led to the error."
            }
          ]
        },
        {
          "category": "Intermediate",
          "points": [
            {
              "title": "Debug Mode",
              "description": "Enable debug mode to get more detailed stack traces. In Project Reactor:\n```java\n// Enable globally (e.g., in a @PostConstruct method)\nHooks.onOperatorDebug();\n\n// Or for specific chains\nFlux.range(1, 10)\n    .checkpoint(\"after range\")\n    .map(i -> i / (i - 5)) // Will cause div by zero error\n    .checkpoint(\"after map\")\n    .subscribe();\n\n// Checkpoint with description and traceback capturing\nFlux.range(1, 10)\n    .checkpoint(\"data source\", true) // Captures full stack trace\n    .map(i -> process(i))\n    .checkpoint(\"processing\")\n    .subscribe();\n    \n// For RxJava\nRxJavaPlugins.setErrorHandler(error -> {\n    // Custom handler for enhanced error reporting\n    Throwable root = error;\n    while (root.getCause() != null) {\n        root = root.getCause();\n    }\n    logger.error(\"Unhandled RxJava error\", root);\n});\n```\nDebug mode and checkpoints are powerful tools for tracking where issues occur in complex reactive pipelines, though they add overhead and should be disabled in production."
            },
            {
              "title": "Debugging in IDE",
              "description": "When using breakpoints in IDEs:\n1. Place breakpoints in lambda expressions inside operators\n2. Use conditional breakpoints for specific data values\n3. For asynchronous code, enable \"suspend thread\" rather than \"suspend VM\" in breakpoint settings\n4. Use \"drop frame\" to retry the execution of a method with corrected values\n\nModern IDEs like IntelliJ IDEA provide specific features for debugging reactive code:\n- Ability to identify which operator in a chain is causing errors\n- Navigation from error stack traces directly to source code\n- Visualization of reactive execution flow\n- Smart step-into functionality that can navigate through reactive operators"
            },
            {
              "title": "Timeouts and Blocking",
              "description": "Add timeouts to detect stuck or slow publishers, and use blocking operators carefully for debugging (never in production code):\n```java\n// Add timeout to detect stalled streams\nflux.timeout(Duration.ofSeconds(5))\n    .doOnError(e -> log.error(\"Stream did not complete in time\", e))\n    .onErrorResume(TimeoutException.class, e -> Flux.empty())\n    .subscribe();\n\n// For debug only: block to inspect a value\nList<Integer> results = flux.collectList().block(); // NEVER in production code\nSystem.out.println(\"Results: \" + results);\n\n// For debug only: replace intermediary results with known values\nFlux<User> userFlux = originalFlux\n    .doOnNext(user -> {\n        if (user.getId().equals(problematicId)) {\n            System.out.println(\"Found problematic user: \" + user);\n        }\n    })\n    // Insert test value for debugging\n    .map(user -> user.getId().equals(problematicId) ? fixedTestUser : user);\n```\nTimely detection of stalled streams is crucial in reactive applications where normal debugging techniques might miss issues in asynchronous processing."
            },
            {
              "title": "Tracing and Metrics",
              "description": "Integrate with distributed tracing and metrics systems:\n```java\n// Reactor with Micrometer\nFlux.range(1, 10)\n    .name(\"my-flux\").tag(\"step\", \"source\") // Add name and tags\n    .metrics() // Enable metrics collection\n    .map(i -> process(i))\n    .name(\"my-flux\").tag(\"step\", \"processed\")\n    .metrics()\n    .subscribe();\n    \n// Integration with distributed tracing (Sleuth/Zipkin/Brave)\nMono<Response> response = WebClient.builder()\n    .filter(TracingWebClientFilter.create(tracer))\n    .build()\n    .get()\n    .uri(\"http://example.com/api/data\")\n    .retrieve()\n    .bodyToMono(Response.class)\n    .name(\"api-request\")\n    .metrics();\n    \n// Exposing JVM metrics with Micrometer\nMeterRegistry registry = new SimpleMeterRegistry();\nJvmMemoryMetrics jvmMemoryMetrics = new JvmMemoryMetrics();\njvmMemoryMetrics.bindTo(registry);\n```\nIntegrating with observability tools is crucial for production environments, as it allows you to track the health and performance of reactive applications in real-time."
            }
          ]
        },
        {
          "category": "Advanced",
          "points": [
            {
              "title": "Reactor Tools",
              "description": "Use `ReactorDebugAgent` for enhanced debugging without performance impact in production:\n```java\n// In your application startup\nimport reactor.tools.agent.ReactorDebugAgent;\n\npublic static void main(String[] args) {\n    ReactorDebugAgent.init();\n    // or\n    ReactorDebugAgent.processExistingClasses();\n    \n    // application code\n}\n```\nThe ReactorDebugAgent uses bytecode instrumentation to add debugging information only when it's needed, making it much more efficient than the Hook-based approach. It can be configured to process all classes or only certain packages."
            },
            {
              "title": "Custom Operator/Hook Testing",
              "description": "For debugging custom operators or integrations, create test pipelines that isolate the problematic section and use custom hooks to intercept signals:\n```java\n// Register a hook for operator errors\nHooks.onOperatorError((error, value) -> {\n    log.error(\"Error processing value: {}\", value, error);\n    return error; // Return original error after logging\n});\n\n// Create a custom hook for debugging subscriptions\nHooks.onEachOperator(operatorSpec ->\n    operatorSpec.operatorStacktrace()\n        .lifter((publisher, subscriber) -> new SignalPeekingSubscriber(subscriber))\n);\n\n// Create a subscriber that logs signals at various levels\npublic class SignalPeekingSubscriber<T> implements CoreSubscriber<T> {\n    private final CoreSubscriber<T> actual;\n    \n    public SignalPeekingSubscriber(CoreSubscriber<T> actual) {\n        this.actual = actual;\n    }\n    \n    @Override\n    public void onSubscribe(Subscription s) {\n        log.info(\"onSubscribe: {}\", s);\n        actual.onSubscribe(s);\n    }\n    \n    @Override\n    public void onNext(T t) {\n        log.info(\"onNext: {}\", t);\n        actual.onNext(t);\n    }\n    \n    @Override\n    public void onError(Throwable t) {\n        log.error(\"onError: {}\", t.getMessage(), t);\n        actual.onError(t);\n    }\n    \n    @Override\n    public void onComplete() {\n        log.info(\"onComplete\");\n        actual.onComplete();\n    }\n}\n```\nCustom hooks and operators provide the deepest level of insight into reactive streams, allowing you to intercept and inspect all aspects of the reactive pipeline."
            },
            {
              "title": "Visualizing Reactive Flows",
              "description": "Some tools can help visualize reactive flows for debugging and understanding:\n\n1. **Marble diagrams**: Using ASCII or tools to visualize the flow\n```\nrange(1, 5): 1--2--3--4--5|\n          map: 2--4--6--8--10|\n       filter: ---6--8--10|\n```\n\n2. **Logging with timestamps**:\n```java\nAtomicLong startTime = new AtomicLong();\nFlux.just(1, 2, 3, 4, 5)\n    .doFirst(() -> startTime.set(System.currentTimeMillis()))\n    .delayElements(Duration.ofMillis(100))\n    .doOnNext(i -> {\n        long elapsed = System.currentTimeMillis() - startTime.get();\n        System.out.printf(\"%dms: Received %d%n\", elapsed, i);\n    })\n    .subscribe();\n```\n\n3. **Using debugging tools** specifically designed for reactive streams:\n   - RxJava's `debug()` operator with a custom RxJavaAssemblyTracking handler\n   - Spring Boot Actuator for WebFlux application monitoring\n   - Custom visualization tools that parse and render application logs in a stream format\n\nThese visualization approaches can help you understand complex reactive flows and identify timing issues that might be hard to spot with traditional debugging."
            },
            {
              "title": "Common Pitfalls and Solutions",
              "description": "Be aware of common reactive debugging challenges and their solutions:\n\n1. **Missing subscription**: No output because `subscribe()` was never called\n   - Solution: Always ensure you're subscribing to start the flow\n   - Debug: Add `.doFirst(() -> System.out.println(\"Subscribed!\"))`\n\n2. **Subscription on wrong scheduler**: Operations running on unexpected threads\n   - Solution: Check your `subscribeOn`/`publishOn` usage\n   - Debug: Add `.doOnSubscribe(s -> System.out.println(\"Subscribed on: \" + Thread.currentThread().getName()))`\n\n3. **Swallowed exceptions**: Exceptions caught but not logged\n   - Solution: Always handle errors or use proper error operators\n   - Debug: Add global error handlers or hooks\n\n4. **Lost signals between async boundaries**: Data disappearing across schedulers\n   - Solution: Ensure proper threading model with correct schedulers\n   - Debug: Add `doOnNext` before and after each scheduler change\n\n5. **Backpressure issues**: System overwhelmed by too many events\n   - Solution: Add proper backpressure handling (`onBackpressureBuffer`, etc.)\n   - Debug: Monitor queue sizes and processing times\n\nIdentifying these common pitfalls can save hours of debugging time in reactive applications."
            }
          ]
        }
      ],
      "relatedQuestions": [
        "java-reactive-testing-core-java-r-8"
      ]
    },
    {
      "id": "java-reactive-composition-core-java-r-16",
      "skillLevel": "basic",
      "shortTitle": "Composing Operations",
      "question": "How do you effectively compose and transform reactive streams in Java?",
      "answerInsights": [
        {
          "category": "Basic",
          "points": [
            {
              "title": "Basic Transformations",
              "description": "Common operators for transforming individual elements:\n```java\nFlux.range(1, 5)\n    .map(i -> i * 2)              // Transform each value: 2, 4, 6, 8, 10\n    .filter(i -> i > 5)           // Keep only values > 5: 6, 8, 10\n    .distinct()                   // Remove duplicates\n    .take(2)                      // Limit to first 2 items: 6, 8\n    .subscribe(System.out::println);\n```\nThese fundamental operators form the building blocks of reactive pipelines. `map` transforms each value independently, `filter` removes items that don't match a predicate, `distinct` eliminates duplicates, and `take` limits the number of items. These can be combined to express complex data processing workflows in a declarative style."
            },
            {
              "title": "Combining Streams",
              "description": "Merge multiple streams together:\n```java\nFlux<String> flux1 = Flux.just(\"A\", \"B\", \"C\");\nFlux<String> flux2 = Flux.just(\"D\", \"E\", \"F\");\n\n// Combine elements from both sources as they arrive\nFlux.merge(flux1, flux2)\n    .subscribe(System.out::println); // Could print: A, D, B, E, C, F (interleaved)\n    \n// Concatenate second source after first completes\nFlux.concat(flux1, flux2)\n    .subscribe(System.out::println); // Always prints: A, B, C, D, E, F (in order)\n    \n// Zip corresponding elements together\nFlux.zip(flux1, flux2, (a, b) -> a + b)\n    .subscribe(System.out::println); // Prints: AD, BE, CF\n    \n// Combine latest values when either source emits\nFlux.combineLatest(flux1, flux2, (a, b) -> a + b)\n    .subscribe(System.out::println); // Combines the most recent values\n```\nThese operators allow you to combine multiple data sources in various ways: `merge` interleaves items from multiple sources as they arrive, `concat` puts one stream after another, `zip` combines corresponding items from multiple streams, and `combineLatest` creates combinations of the most recent values from each stream."
            },
            {
              "title": "Error Handling",
              "description": "Handle exceptions in the reactive stream:\n```java\nFlux.just(1, 2, 0, 4, 5)\n    .map(i -> 10 / i)                     // Will throw when i=0\n    .onErrorReturn(0)                     // Replace error with default value\n    .subscribe(System.out::println);      // Prints: 10, 5, 0 (then completes)\n    \n// Alternative error handling approaches\nFlux.just(1, 2, 0, 4, 5)\n    .map(i -> {\n        try {\n            return 10 / i;\n        } catch (ArithmeticException e) {\n            return 0;                      // Handle locally\n        }\n    })\n    .subscribe(System.out::println);       // Prints: 10, 5, 0, 2, 2\n    \n// Switch to a fallback stream on error\nFlux.just(1, 2, 0, 4, 5)\n    .map(i -> 10 / i)                      // Will throw when i=0\n    .onErrorResume(e -> Flux.just(-1, -2)) // Switch to fallback stream on error\n    .subscribe(System.out::println);       // Prints: 10, 5, -1, -2\n    \n// Convert the error type\nFlux.just(1, 2, 0, 4, 5)\n    .map(i -> 10 / i)\n    .onErrorMap(ArithmeticException.class, \n        e -> new CustomException(\"Division by zero\", e))\n    .subscribe(\n        System.out::println,\n        error -> System.err.println(\"Error: \" + error.getMessage())\n    );\n```\nThese error handling operators allow for resilient reactive pipelines that can recover from failures in various ways: `onErrorReturn` provides a default value, `onErrorResume` switches to an alternative data source, and `onErrorMap` translates technical exceptions to more meaningful domain errors."
            }
          ]
        },
        {
          "category": "Intermediate",
          "points": [
            {
              "title": "Flattening Nested Streams",
              "description": "Handle nested streams with various flatMap operators:\n```java\n// Flatmap example: for each user, fetch their orders\nFlux<User> users = userRepository.findAll();\n\n// Process each user's orders (sequentially)\nusers.flatMap(user -> orderRepository.findByUser(user.getId()))\n     .subscribe(order -> processOrder(order));\n     \n// Process concurrently (up to 5 users at a time)\nusers.flatMap(user -> orderRepository.findByUser(user.getId()),\n               5)  // concurrency hint\n     .subscribe(order -> processOrder(order));\n     \n// Keep original order using concatMap (slower but ordered)\nusers.concatMap(user -> orderRepository.findByUser(user.getId()))\n     .subscribe(order -> processOrder(order));\n     \n// SwitchMap - cancel previous inner publisher when a new one arrives\nFlux<String> searchTerms = searchBar.textChanges(); // User typing in search box\nsearchTerms\n    .switchMap(term -> searchService.search(term)) // Only most recent search matters\n    .subscribe(result -> displayResults(result));\n```\nThese flattening operators are essential for working with nested asynchronous operations: `flatMap` processes inner streams in parallel, `concatMap` preserves ordering at the cost of serializing operations, and `switchMap` cancels ongoing operations when new ones arrive, which is perfect for scenarios like search-as-you-type where only the latest result matters."
            },
            {
              "title": "Conditional Processing",
              "description": "Apply different logic based on conditions:\n```java\n// Dynamically choose a source based on a condition\nMono<String> result = Mono.just(\"input\")\n    .flatMap(input -> {\n        if (input.length() > 10) {\n            return serviceA.process(input);\n        } else {\n            return serviceB.process(input);\n        }\n    });\n    \n// Switch to alternate stream if original is empty\nMono<User> user = userRepository.findById(id)\n    .switchIfEmpty(Mono.just(User.defaultUser()));\n    \n// Apply different transformations based on type\nFlux<Object> mixed = Flux.just(\"string\", 123, \"another\", 456);\nmixed.handle((item, sink) -> {\n    if (item instanceof String) {\n        sink.next(\"String: \" + item);\n    } else if (item instanceof Integer) {\n        sink.next(\"Number: \" + item);\n    }\n});\n\n// Filter with side effects for rejected items\nFlux<Order> orders = orderService.getOrders();\norders.filter(order -> {\n        if (order.isValid()) {\n            return true;\n        } else {\n            reportInvalidOrder(order);\n            return false;\n        }\n    })\n    .subscribe(this::processValidOrder);\n```\nThese conditional patterns enable complex routing and filtering behaviors: dynamic service selection, fallbacks for empty results, type-specific processing, and filtering with side effects for rejected items."
            },
            {
              "title": "Time-Based Operations",
              "description": "Operators for handling time aspects of streams:\n```java\n// Throttle events to at most one per second\nclickFlux.sample(Duration.ofSeconds(1))\n         .subscribe(click -> processClick(click));\n         \n// Group events into 2-second windows\nmetricFlux.window(Duration.ofSeconds(2))\n          .flatMap(windowFlux -> windowFlux.reduce(0, Integer::sum))\n          .subscribe(sum -> System.out.println(\"Sum in window: \" + sum));\n          \n// Add timeout to operations\nuserRepository.findById(id)\n    .timeout(Duration.ofSeconds(3))\n    .onErrorResume(TimeoutException.class, \n                   e -> Mono.just(User.defaultUser()))\n    .subscribe(user -> displayUser(user));\n    \n// Delay elements\nFlux.range(1, 5)\n    .delayElements(Duration.ofMillis(100)) // 100ms between emissions\n    .subscribe(i -> System.out.println(\"Received: \" + i));\n    \n// Periodic emissions\nFlux<Long> ticks = Flux.interval(Duration.ofSeconds(1))\n    .take(Duration.ofMinutes(5)); // Emit for 5 minutes\n    \n// Debounce - wait for a quiet period before emitting\ntextInput.debounce(Duration.ofMillis(300)) // Wait 300ms of inactivity\n    .subscribe(text -> search(text)); // Only search after user stops typing\n```\nThese time-based operators are crucial for handling the temporal aspects of reactive streams: `sample` reduces the frequency of fast events, `window` groups events in time periods, `timeout` prevents operations from taking too long, `delayElements` introduces spacing between emissions, `interval` creates periodic events, and `debounce` waits for quiet periods before processing events."
            }
          ]
        },
        {
          "category": "Advanced",
          "points": [
            {
              "title": "Dynamic Subscription Management",
              "description": "Control or dynamically modify subscriptions:\n```java\n// Switch to new stream when a condition changes\nFlux<String> source = Flux.interval(Duration.ofSeconds(1))\n    .map(i -> \"Source 1: \" + i);\n    \nFlux<String> trigger = Flux.just(\"switch\")\n    .delayElements(Duration.ofSeconds(5));\n    \nFlux<String> alternate = Flux.interval(Duration.ofMillis(500))\n    .map(i -> \"Source 2: \" + i);\n    \n// When trigger emits, switch to alternate source\nsource.takeUntilOther(trigger)\n      .concatWith(alternate)\n      .subscribe(System.out::println);\n      \n// Or use switchMap for more dynamic switching\nMono<String> userIdMono = getCurrentUserId(); // Changes over time\n\nuserIdMono\n    .switchMap(userId -> userRepository.findById(userId)\n                         .flatMapMany(user -> activityRepository.findByUser(user)))\n    .subscribe(activity -> displayActivity(activity));\n    \n// Disposable for controlling subscriptions programmatically\nDisposable subscription = dataStream\n    .subscribe(data -> processData(data));\n    \n// Later, cancelling the subscription\nif (shouldStop) {\n    subscription.dispose();\n}\n```\nThese dynamic subscription patterns give you control over when streams start, stop, or change: `takeUntilOther` limits a stream until a signal arrives, `concatWith` chains streams together, `switchMap` dynamically changes data sources, and manual subscription disposal gives you programmatic control over stream lifecycle."
            },
            {
              "title": "Controlled Parallelism",
              "description": "Fine control over parallelism and scheduling:\n```java\n// Process in parallel with controlled parallelism\nFlux.range(1, 100)\n    .parallel(4)                          // Split into 4 rails\n    .runOn(Schedulers.parallel())         // Use parallel scheduler\n    .map(i -> computeIntensiveFunction(i))\n    .sequential()                         // Merge back to single stream\n    .subscribe(result -> saveResult(result));\n    \n// Schedule different operations on appropriate schedulers\nuserInteraction\n    .subscribeOn(Schedulers.boundedElastic()) // Handle on I/O thread\n    .map(input -> parseInput(input))          // CPU-bound\n    .publishOn(Schedulers.parallel())         // Switch to computation thread\n    .map(data -> performHeavyCalculation(data)) // CPU-intensive\n    .publishOn(Schedulers.boundedElastic())   // Switch back to I/O thread\n    .flatMap(result -> databaseRepository.save(result)) // I/O bound\n    .subscribe();\n    \n// Custom thread pool for specific operations\nExecutorService executor = Executors.newFixedThreadPool(\n    Runtime.getRuntime().availableProcessors(),\n    new ThreadFactoryBuilder().setNameFormat(\"custom-pool-%d\").build()\n);\nScheduler customScheduler = Schedulers.fromExecutor(executor);\n\ndataStream\n    .publishOn(customScheduler)\n    .map(this::processWithCustomRequirements)\n    .subscribe();\n```\nThis controlled parallelism enables optimal resource utilization: the `parallel` operator splits processing across multiple cores, appropriate schedulers ensure operations run on the right type of thread (I/O vs. computation), and custom thread pools allow for specialized threading needs."
            },
            {
              "title": "Reusable Compositions",
              "description": "Create reusable operators by composing existing ones:\n```java\n// Create a reusable transformation\npublic <T> Function<Flux<T>, Flux<T>> logAndRetry(String name) {\n    return flux -> flux\n        .doOnNext(item -> log.info(\"Processing {} item: {}\", name, item))\n        .doOnError(e -> log.error(\"Error in {}: {}\", name, e.getMessage()))\n        .retry(3)\n        .timeout(Duration.ofSeconds(10));\n}\n\n// Use the composition\nFlux<Order> orders = orderRepository.findAll()\n    .transform(logAndRetry(\"order-processing\"));\n    \n// Using transform for multiple steps\nFlux<UserActivity> activities = userActivityRepository.findByUserId(userId)\n    .transform(flux -> applySecurityFilters(flux))\n    .transform(flux -> enrichWithUserInfo(flux))\n    .transform(flux -> applyTimeFilters(flux))\n    .transform(logAndRetry(\"activity-processing\"));\n    \n// Custom operator creation\npublic <T> Function<Flux<T>, Flux<T>> retryWithBackoff(\n        int maxRetries, Duration initialDelay) {\n    return flux -> flux.retryWhen(Retry.backoff(maxRetries, initialDelay)\n        .maxBackoff(Duration.ofMinutes(1))\n        .filter(e -> e instanceof TransientException));\n}\n\nFlux<Data> resilientData = dataSource.getData()\n    .transform(retryWithBackoff(3, Duration.ofMillis(100)));\n```\nReusable compositions promote code reuse and cleaner, more maintainable reactive pipelines: the `transform` operator allows applying complex transformations as a unit, and custom operator functions encapsulate common patterns like retrying with backoff or adding consistent logging."
            },
            {
              "title": "Advanced Combination Patterns",
              "description": "Complex patterns for combining multiple asynchronous operations:\n\n1. **Gather-scatter**: Process data from multiple sources and combine results\n```java\nFlux<Integer> performGatherScatter(Flux<Request> requests) {\n    return requests.flatMap(request -> {\n        // Parallel requests to multiple services (scatter)\n        Mono<Data> dataFromA = serviceA.process(request).subscribeOn(Schedulers.parallel());\n        Mono<Data> dataFromB = serviceB.process(request).subscribeOn(Schedulers.parallel());\n        Mono<Data> dataFromC = serviceC.process(request).subscribeOn(Schedulers.parallel());\n        \n        // Combine results (gather)\n        return Mono.zip(dataFromA, dataFromB, dataFromC)\n            .map(tuple -> aggregateResults(tuple.getT1(), tuple.getT2(), tuple.getT3()));\n    }, 10); // Limited concurrency\n}\n```\n\n2. **Prioritized sources**: Try primary source, fall back to secondary with timeout\n```java\nMono<Data> getPrioritizedData(String id) {\n    return primarySource.getData(id)\n        .timeout(Duration.ofMillis(200))  // Try primary with short timeout\n        .onErrorResume(e -> {\n            log.warn(\"Primary source failed or timed out, using secondary\", e);\n            return secondarySource.getData(id);\n        });\n}\n```\n\n3. **Windowed operations**: Process data in overlapping windows\n```java\nFlux<Stats> getMovingAverages(Flux<Measurement> measurements) {\n    return measurements\n        // Create sliding windows of 100 measurements with 25 measurements overlap\n        .window(100, 25)\n        // Calculate statistics for each window\n        .flatMap(window -> window.collectList()\n                                .map(this::calculateStatistics));\n}\n```\nThese advanced patterns enable sophisticated data processing flows that would be complex to implement imperatively but become clear and concise with reactive operators."
            }
          ]
        }
      ],
      "relatedQuestions": [
        "java-project-reactor-core-java-r-4",
        "java-rxjava-core-java-r-5"
      ]
    }
  ]
}